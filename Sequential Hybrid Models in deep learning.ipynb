{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e979a61-2f0a-4608-9bfb-c0f84c3eddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.datasets import load_iris\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.initializers import he_uniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af5c98-8b72-4652-8500-afb5c7a7300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file or other source\n",
    "file_path = r\"F:\\other student data\\BKUC MS\\BKUC Bilal\\pca80.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the last column is the target variable and all other columns are features\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f781d-c012-41c2-bb51-dd4310195786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define a traditional machine learning model (Random Forest as an example)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the traditional model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ccd3f-37d9-44c8-a5be-590323f6fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions or use features from the Random Forest model\n",
    "X_train_rf = rf_model.predict_proba(X_train)\n",
    "X_test_rf = rf_model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed82ba5-94d1-4062-be57-19eeb56789f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple Neural Network using Keras Sequential API\n",
    "deep_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_rf.shape[1],), kernel_initializer=he_uniform()),\n",
    "    Dropout(0.2),  # Adding dropout with rate 0.2\n",
    "    Dense(64, activation='relu', kernel_initializer=he_uniform()),\n",
    "   # Dropout(0.4),  # Adding dropout with rate 0.2\n",
    "    Dense(32, activation='relu', kernel_initializer=he_uniform()),\n",
    "   # Dropout(0.3), \n",
    "    Dense(16, activation='relu', kernel_initializer=he_uniform()),\n",
    "   # Dropout(0.2), \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer and custom learning rate\n",
    "adam_optimizer = Adam(learning_rate=0.001)  # Specify learning rate\n",
    "deep_model.compile(optimizer=adam_optimizer,\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train the model using features from Step 1 (Random Forest predictions)\n",
    "history = deep_model.fit(X_train_rf, y_train,\n",
    "                         epochs=100,\n",
    "                         batch_size=32,\n",
    "                         validation_data=(X_test_rf, y_test),\n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec720610-3102-4801-af3d-394e4d3357f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Sequential Hybrid Model on test data\n",
    "y_pred_deep = deep_model.predict(X_test_rf)\n",
    "y_pred_deep_classes = np.argmax(y_pred_deep, axis=1)  # Convert probabilities to class labels\n",
    "accuracy_deep = accuracy_score(y_test, y_pred_deep_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a7224-32ad-42d0-9d4b-ea1d1f6b453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn import metrics\n",
    "\n",
    "# Evaluate the Sequential Hybrid Model on test data\n",
    "y_pred_deep = deep_model.predict(X_test_rf)\n",
    "y_pred_deep_classes = (y_pred_deep > 0.5).astype(int)  # Convert probabilities to binary class labels\n",
    "\n",
    "# Accuracy\n",
    "accuracy_deep = accuracy_score(y_test, y_pred_deep_classes)\n",
    "print(f\"Sequential Hybrid Model Accuracy: {accuracy_deep:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_deep_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "sensitivity = recall_score(y_test, y_pred_deep_classes)\n",
    "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
    "\n",
    "# Specificity\n",
    "specificity = metrics.recall_score(y_test, y_pred_deep_classes, pos_label=0)\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred_deep_classes)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = metrics.matthews_corrcoef(y_test, y_pred_deep_classes)\n",
    "print(f\"MCC: {mcc:.2f}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred_deep_classes)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_deep_classes)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_deep_classes)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# P-test and T-test (you need to define how you want to perform these tests based on your hypothesis)\n",
    "# For example:\n",
    "# p_value = ...\n",
    "# t_statistic = ...\n",
    "\n",
    "# Print or use p_value and t_statistic as needed\n",
    "# print(f\"P-Test: {p_value:.2f}\")\n",
    "# print(f\"T-Test: {t_statistic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19237648-cb9e-4ba2-8794-46cc82cc9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training & validation accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=3)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=3)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Model Accuracy.png\", bbox_inches='tight', transparent=False)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ecec7-774a-4730-ac3c-118dbd551c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Specify the save path\n",
    "save_path = os.path.join(home_dir, 'model_loss_plot.png') #, transparent=False\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=3)\n",
    "plt.plot(history.history['val_loss'], label='Test Loss', linewidth=3)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss (%)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.title('Model Loss', fontsize=16)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b261f8-1df0-4078-8f62-3e6e8cb47ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming you have PCA applied after preprocessing steps\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Plot PCA visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', edgecolor='k', s=50, alpha=0.7)\n",
    "plt.title('PCA of Training Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"PCA of Training Data.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6881d-49e8-4c6b-827a-fde45ebbb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_pred_deep_proba = deep_model.predict(X_test_rf)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_deep_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='b', marker='o', markersize=5, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Sequential Hybrid Model')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Precision-Recall Curve.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f37fe5-7ee5-4e62-a881-24235d58a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting with different line styles, markers, and widths\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linestyle='-.', linewidth=2, marker='o')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linestyle='--', linewidth=2, marker='^')\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linestyle='-.', linewidth=2, marker='s')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linestyle=':', linewidth=2, marker='x')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curve')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(\"Learning Curve.png\", bbox_inches='tight', transparent=False)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Assuming `history` is your Keras history object\n",
    "plot_learning_curve(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d517f79-fadb-4c1b-acf5-4d0d0669e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming rf_model, data, and indices are defined as in your context\n",
    "\n",
    "# Extract feature importances from Random Forest model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = data.columns[:-1]  # Assuming the last column is the target variable\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define a colormap\n",
    "colors = plt.cm.viridis(feature_importances / max(feature_importances))\n",
    "\n",
    "# Plot bars\n",
    "bars = plt.bar(range(len(indices)), feature_importances[indices], align='center', color=colors)\n",
    "\n",
    "# Customize ticks and labels\n",
    "plt.xticks(range(len(indices)), feature_names[indices], rotation=90)\n",
    "plt.gca().set_xticks(range(min(len(indices), 100)))  # Show up to top 67 features\n",
    "plt.gca().set_xticklabels(feature_names[indices][:0], rotation=90)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "#plt.title('Feature Importance - Random Forest')\n",
    "\n",
    "# Create a ScalarMappable object\n",
    "mappable = plt.cm.ScalarMappable(cmap='viridis')\n",
    "mappable.set_array(feature_importances)\n",
    "\n",
    "# Add color bar with specified Axes\n",
    "cbar = plt.colorbar(mappable, ax=plt.gca())\n",
    "cbar.set_label('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Feature Importance.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3e53a-b476-4735-8fa9-51e4138a38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='k')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Class Distribution.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187831c-c806-4973-8f5d-88757ceaf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming only two features after PCA\n",
    "if X_train_pca.shape[1] == 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "    y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    Z = deep_model.predict(np.c_[xx.ravel(), yy.ravel()])[:, 0]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', edgecolor='k', s=50, alpha=0.7)\n",
    "    plt.title('Decision Boundary - Sequential Hybrid Model')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar()\n",
    "  \n",
    "    plt.savefig(\"Decision Boundary.png\", bbox_inches='tight', transparent=False)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot plot decision boundary. Ensure PCA reduces data to 2 dimensions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de16181-4fa6-411e-b28c-659f076b99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, deep_model.predict(X_test_rf)[:, 0], n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=3, label='Calibration Curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Calibration Curve.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f650b8-8f44-4192-8c92-40a404556b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming regression task and `y_test` and `y_pred_deep` are continuous values\n",
    "if np.issubdtype(y_test.dtype, np.number) and np.issubdtype(y_pred_deep.dtype, np.number):\n",
    "    residuals = y_test - y_pred_deep.flatten()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    # Customizing scatter plot with different colors and markers\n",
    "    plt.scatter(y_pred_deep, residuals, c=residuals, cmap='coolwarm', edgecolor='k', s=500, alpha=0.7)\n",
    "    \n",
    "    # Adding color bar to indicate residual values\n",
    "    plt.colorbar(label='Residual')\n",
    "    \n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(\"Residual Plot.png\", bbox_inches='tight', transparent=False)\n",
    "else:\n",
    "    print(\"Cannot plot residuals. Ensure `y_test` and `y_pred_deep` are continuous values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e9f46-1e20-48c4-9b19-f4ecb1abfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scikitplot.metrics import plot_cumulative_gain\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plot_cumulative_gain(y_test, deep_model.predict_proba(X_test_rf))\n",
    "# plt.title('Cumulative Gain Curve')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73aeef4-f2e0-4b0b-8fbe-804fe30245ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scikitplot.metrics import plot_lift_curve\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plot_lift_curve(y_test, deep_model.predict_proba(X_test_rf))\n",
    "# plt.title('Lift Curve')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3f912-5b74-4de4-96ac-cbf3910ab99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example of validation curve for max_depth in a decision tree\n",
    "param_range = np.arange(1, 20, 2)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(), X_train, y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "    scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "\n",
    "# Define colors and line widths\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"orange\", marker='o', markersize=8)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"orange\", lw=2)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"blue\", marker='s', markersize=8)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"blue\", lw=2)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Cross-validation score.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059a94d-4d76-4623-a3de-aff372dac9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example of validation curve for max_depth in a decision tree\n",
    "param_range = np.arange(1, 20, 2)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(), X_train, y_train, param_name=\"max_depth\", param_range=param_range,\n",
    "    scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "\n",
    "# Plot training scores\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"darkorange\", lw=2)\n",
    "\n",
    "# Plot cross-validation scores\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"navy\", lw=2)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Cross-validation score.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d36fe-faef-46d7-bcfc-fd5a8c7b9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate a sample dataset (replace with your actual data loading)\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Example of comparing multiple classifiers using cross-validation scores\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('SVM', SVC(probability=True)),\n",
    "    ('AdaBoost', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Mean Accuracy = {np.mean(cv_results):.2f}, Std = {np.std(cv_results):.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Model Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"Model Comparison.png\", bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b3f3d-12ad-4b47-8566-959d96b743ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of visualizing word embeddings in a deep learning model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# Assuming `embedding_layer` is an Embedding layer in `deep_model`\n",
    "if 'deep_model' in locals():\n",
    "    for layer in deep_model.layers:\n",
    "        if isinstance(layer, Embedding):\n",
    "            embeddings = layer.get_weights()[0]\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            for i in range(embeddings.shape[0]):\n",
    "                plt.text(embeddings[i, 0], embeddings[i, 1], str(i))\n",
    "            plt.title('Embedding Visualization')\n",
    "            plt.xlabel('Dimension 1')\n",
    "            plt.ylabel('Dimension 2')\n",
    "            plt.show()\n",
    "            break\n",
    "else:\n",
    "    print(\"Deep learning model (`deep_model`) not found. Please ensure it is defined and trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9230e3a-5f80-42c8-91b4-68cdd8a0336d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19defad2-b14e-4fa5-98a3-2387da18ec11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a306cd-7e0c-49ba-96dc-1a18222a9fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b302d-8952-4946-9d38-8155649d7163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c042a92-a2b5-4a5f-be3a-2cecf6db8d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
